# AI Chat Core Environment Variables
# --------------------------------
# This file contains environment variables used by the Python FastAPI AI Chat Core service.
# Copy this file to .env in the same directory and fill in your values.
# NEVER commit the actual .env file to version control.

# Environment
ENVIRONMENT=development # Options: development, test, production

# OpenAI API Configuration
# Required: OpenAI API key for model access
OPENAI_API_KEY= 

# Default Model Configuration
# Required: Default model settings
DEFAULT_MODEL=gpt-4o # Options: gpt-4o, gpt-4-turbo, gpt-3.5-turbo, etc.
DEFAULT_MAX_TOKENS=1000 # Maximum number of tokens in responses
DEFAULT_TEMPERATURE=0.7 # Controls randomness (0.0-1.0)

# Supabase Configuration
# Required: Supabase connection details for database access
SUPABASE_URL= 
SUPABASE_ANON_KEY= 
SUPABASE_SERVICE_ROLE_KEY= 

# API Configuration
# Required: API server settings
API_HOST=0.0.0.0 # Host to bind the server to
API_PORT=4000 # Port to run the server on
API_ROOT_PATH=/api/v1 # Root path for API endpoints
CORS_ORIGINS=http://localhost:3000,http://localhost:3001 # Comma-separated list of allowed origins

# Authentication
# Required: JWT settings for authentication
JWT_SECRET= 
JWT_ALGORITHM=HS256 # Algorithm used for JWT

# Logging Configuration
# Optional: Configure logging behavior
LOG_LEVEL=INFO # Options: DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_FORMAT=json # Options: json, text

# Rate Limiting
# Optional: Configure rate limiting to prevent abuse
RATE_LIMIT_REQUESTS=60 # Number of requests allowed
RATE_LIMIT_PERIOD=60 # Time period in seconds

# Cache Configuration
# Optional: Configure caching behavior
CACHE_TTL=300 # Cache time-to-live in seconds

# Multi-Model Configuration
# Required for multi-model orchestration
ENABLE_MULTI_MODEL=true # Enable multi-model support
AVAILABLE_MODELS=gpt-4o,gpt-4-turbo,gpt-3.5-turbo,claude-3-opus,claude-3-sonnet # Comma-separated list of available models
ANTHROPIC_API_KEY=